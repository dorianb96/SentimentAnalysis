{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Movie Reviews - Kaggle\n",
    "\n",
    "\"There's a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"\n",
    "\n",
    "The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon's Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#classifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline :\n",
    "    - read file\n",
    "    - tokenize into words\n",
    "    - lowercase\n",
    "    - remove stopwords\n",
    "    - stemming\n",
    "    - add 1-grams and 2-grams to featurs\n",
    "    - implemented with tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data: 156060\n",
      "size of test data: 66292\n"
     ]
    }
   ],
   "source": [
    "train_data = [x.split('\\t') for x in open('train_rotten_tomatoes.tsv','r').readlines()][1:]\n",
    "test_data = [x.split('\\t') for x in open('test_rotten_tomatoes.tsv','r').readlines()][1:]\n",
    "\n",
    "train_x_raw = [x[2].lower() for x in train_data]\n",
    "train_y = [int(x[3].rstrip('\\n')) for x in train_data]\n",
    "\n",
    "paragraph_id = [x[0].lower() for x in test_data]\n",
    "test_x_raw = [x[2].lower() for x in test_data]\n",
    "#test_y = [x[3].rstrip('\\n') for x in test_data] --> no predictions, we need to figure them out!\n",
    "\n",
    "print('size of training data:',len(train_x_raw))\n",
    "print('size of test data:',len(test_x_raw))\n",
    "    \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, sublinear_tf=True, stop_words='english',ngram_range=(1,3))\n",
    "train_X =  tfidf.fit_transform(train_x_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing classifiers (for multiclass classification)\n",
    "    - cross validation to get a gauge of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* note that cross validation usually gives pessmistic scores\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False) : score =  0.520037157072\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0) : score =  0.524451718822\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, solver='lsqr', tol=0.01) : score =  0.529071809662\n",
      "OneVsRestClassifier(estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, solver='lsqr', tol=0.01),\n",
      "          n_jobs=1) : score =  0.529071809662\n",
      "OneVsOneClassifier(estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, solver='lsqr', tol=0.01),\n",
      "          n_jobs=1) : score =  0.533787950659\n",
      "PassiveAggressiveClassifier(C=1.0, fit_intercept=True, loss='hinge',\n",
      "              n_iter=50, n_jobs=1, random_state=None, shuffle=True,\n",
      "              verbose=0, warm_start=False) : score =  0.509335842217\n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=200, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False) : score =  0.490561146207\n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True) : score =  0.437407729377\n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True) : score =  0.443110683458\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(alpha=.0001, n_iter=50,penalty=\"elasticnet\")\n",
    "svc = LinearSVC(dual=False, tol=1e-3)\n",
    "ridge = RidgeClassifier(tol=1e-2, solver=\"lsqr\")\n",
    "#\n",
    "ova_ridge = OneVsOneClassifier(RidgeClassifier(tol=1e-2, solver=\"lsqr\"))\n",
    "ovr_ridge = OneVsRestClassifier(RidgeClassifier(tol=1e-2, solver=\"lsqr\"))\n",
    "#\n",
    "pas_agg = PassiveAggressiveClassifier(n_iter=50)\n",
    "percep = Perceptron(n_iter=200)\n",
    "multi_nb = MultinomialNB(alpha=.01)\n",
    "bern_nb = BernoulliNB(alpha=.01)\n",
    "\n",
    "\n",
    "classifiers = [sgd, svc,ridge, ovr_ridge, ova_ridge, pas_agg, percep, multi_nb,bern_nb]\n",
    "\n",
    "max_score = 0\n",
    "best_clf = None\n",
    "print('* note that cross validation usually gives pessmistic scores')\n",
    "\n",
    "for clf in classifiers:\n",
    "    score = cross_val_score(clf, train_X, train_y, cv=5).mean()\n",
    "    if score > max_score:\n",
    "        max_score=score\n",
    "        best_clf=clf\n",
    "    print(clf,': score = ',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf.fit(train_X, train_y)\n",
    "y=best_clf.predict(tfidf.transform(test_x_raw))\n",
    "result = zip(paragraph_id,y)\n",
    "f = open('subimission.txt', 'w')\n",
    "f.write('PhraseId,Sentiment\\n')\n",
    "for t in result:\n",
    "    line = ','.join(str(x) for x in t)\n",
    "    f.write(line + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reflection\n",
    "\n",
    "- The result is ok for my time investment, the kaggle submission accuracy is 0.60033\n",
    "- This is around 440/860 places. The best result on Kaggle is 0.76, top 10 average is 0.70\n",
    "\n",
    "\n",
    "- A prepackaged library from Stanford http://nlp.stanford.edu/sentiment/ using Deep Learning for Sentiment Analysis with the 5 categories classification we used above yields very good results of 0.65-0.7. \n",
    "\n",
    "- So maybe trying Keras or other Deep Learning libraries would be a good approach.\n",
    "\n",
    "\n",
    "- One more thing is that I didn't use Random Forest because of the time it takes to train them.  That might be interesting to try \n",
    "\n",
    "\n",
    "- I should have done more feature extraction: \n",
    "    - Dependency Parsing to put all the parts of one sentence together\n",
    "    - extra features using NLTK's Sentiment Analysis"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
